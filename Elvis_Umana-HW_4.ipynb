{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ['']*60\n",
    "Y = ['']*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,20):\n",
    "    X[i] = open('/Users/elvis/Downloads/hw4-1/languageID/e' + str(i) + '.txt','r').read()\n",
    "    X[i+20] = open('/Users/elvis/Downloads/hw4-1/languageID/j' + str(i) + '.txt','r').read()\n",
    "    X[i+40] = open('/Users/elvis/Downloads/hw4-1/languageID/s' + str(i) + '.txt','r').read()\n",
    "    Y[i] = 'e'\n",
    "    Y[i+20] = 'j'\n",
    "    Y[i+40] = 's'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prior(lang_target, text, langs):\n",
    "    count = 0\n",
    "    for i in langs:\n",
    "        if i == lang_target:\n",
    "            count = count + 1\n",
    "    prior_calc = (count + 0.5)/(len(langs) + 3*0.5)\n",
    "    return(prior_calc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_prior = Prior('e', X[:10] + X[20:30] + X[40:50], Y[:10] + Y[20:30] + Y[40:50])\n",
    "j_prior = Prior('j', X[:10] + X[20:30] + X[40:50], Y[:10] + Y[20:30] + Y[40:50])\n",
    "s_prior = Prior('s', X[:10] + X[20:30] + X[40:50], Y[:10] + Y[20:30] + Y[40:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Y = e) = 0.3333333333333333\n",
      "P(Y = j) = 0.3333333333333333\n",
      "P(Y = s) = 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"P(Y = e) = \" + str(e_prior) + \"\\nP(Y = j) = \" + str(j_prior) + \"\\nP(Y = s) = \" + str(s_prior))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Theta_vec(text, langs):\n",
    "    count = [0]*27\n",
    "    theta = [0.0]*27\n",
    "    for i in text:\n",
    "        for j in i:\n",
    "            if j == 'a':\n",
    "                count[0] = count[0] + 1\n",
    "            if j == 'b':\n",
    "                count[1] = count[1] + 1\n",
    "            if j == 'c':\n",
    "                count[2] = count[2] + 1\n",
    "            if j == 'd':\n",
    "                count[3] = count[3] + 1\n",
    "            if j == 'e':\n",
    "                count[4] = count[4] + 1\n",
    "            if j == 'f':\n",
    "                count[5] = count[5] + 1\n",
    "            if j == 'g':\n",
    "                count[6] = count[6] + 1\n",
    "            if j == 'h':\n",
    "                count[7] = count[7] + 1\n",
    "            if j == 'i':\n",
    "                count[8] = count[8] + 1\n",
    "            if j == 'j':\n",
    "                count[9] = count[9] + 1\n",
    "            if j == 'k':\n",
    "                count[10] = count[10] + 1\n",
    "            if j == 'l':\n",
    "                count[11] = count[11] + 1\n",
    "            if j == 'm':\n",
    "                count[12] = count[12] + 1\n",
    "            if j == 'n':\n",
    "                count[13] = count[13] + 1\n",
    "            if j == 'o':\n",
    "                count[14] = count[14] + 1\n",
    "            if j == 'p':\n",
    "                count[15] = count[15] + 1\n",
    "            if j == 'q':\n",
    "                count[16] = count[16] + 1\n",
    "            if j == 'r':\n",
    "                count[17] = count[17] + 1\n",
    "            if j == 's':\n",
    "                count[18] = count[18] + 1\n",
    "            if j == 't':\n",
    "                count[19] = count[19] + 1\n",
    "            if j == 'u':\n",
    "                count[20] = count[20] + 1\n",
    "            if j == 'v':\n",
    "                count[21] = count[21] + 1\n",
    "            if j == 'w':\n",
    "                count[22] = count[22] + 1\n",
    "            if j == 'x':\n",
    "                count[23] = count[23] + 1\n",
    "            if j == 'y':\n",
    "                count[24] = count[24] + 1\n",
    "            if j == 'z':\n",
    "                count[25] = count[25] + 1\n",
    "            if j == ' ':\n",
    "                count[26] = count[26] + 1\n",
    "    for i in range(0,27):\n",
    "        theta[i] = count[i]/sum(count)\n",
    "    return(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The multinomial parameter vector for English is:\n",
      "[0.06  0.011 0.021 0.022 0.105 0.019 0.017 0.047 0.055 0.001 0.004 0.029\n",
      " 0.021 0.058 0.064 0.017 0.001 0.054 0.066 0.08  0.027 0.009 0.015 0.001\n",
      " 0.014 0.001 0.179]\n"
     ]
    }
   ],
   "source": [
    "e_theta = Theta_vec(X[:10], Y[:10])\n",
    "print(\"The multinomial parameter vector for English is:\\n\" + str(np.round(e_theta, 3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The multinomial parameter vector for Japanese is:\n",
      "[0.132 0.011 0.005 0.017 0.06  0.004 0.014 0.032 0.097 0.002 0.057 0.001\n",
      " 0.04  0.057 0.091 0.001 0.    0.043 0.042 0.057 0.071 0.    0.02  0.\n",
      " 0.014 0.008 0.124]\n"
     ]
    }
   ],
   "source": [
    "j_theta = Theta_vec(X[20:30], Y[:10])\n",
    "print(\"The multinomial parameter vector for Japanese is:\\n\" + str(np.round(j_theta, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The multinomial parameter vector for Spanish is:\n",
      "[0.105 0.008 0.038 0.04  0.114 0.009 0.007 0.005 0.05  0.007 0.    0.053\n",
      " 0.026 0.054 0.073 0.024 0.008 0.059 0.066 0.036 0.034 0.006 0.    0.002\n",
      " 0.008 0.003 0.168]\n"
     ]
    }
   ],
   "source": [
    "s_theta = Theta_vec(X[40:50], Y[:10])\n",
    "print(\"The multinomial parameter vector for Spanish is:\\n\" + str(np.round(s_theta, 3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Count_vec(text, langs):\n",
    "    count = [0]*27\n",
    "    for i in text:\n",
    "        for j in i:\n",
    "            if j == 'a':\n",
    "                count[0] = count[0] + 1\n",
    "            if j == 'b':\n",
    "                count[1] = count[1] + 1\n",
    "            if j == 'c':\n",
    "                count[2] = count[2] + 1\n",
    "            if j == 'd':\n",
    "                count[3] = count[3] + 1\n",
    "            if j == 'e':\n",
    "                count[4] = count[4] + 1\n",
    "            if j == 'f':\n",
    "                count[5] = count[5] + 1\n",
    "            if j == 'g':\n",
    "                count[6] = count[6] + 1\n",
    "            if j == 'h':\n",
    "                count[7] = count[7] + 1\n",
    "            if j == 'i':\n",
    "                count[8] = count[8] + 1\n",
    "            if j == 'j':\n",
    "                count[9] = count[9] + 1\n",
    "            if j == 'k':\n",
    "                count[10] = count[10] + 1\n",
    "            if j == 'l':\n",
    "                count[11] = count[11] + 1\n",
    "            if j == 'm':\n",
    "                count[12] = count[12] + 1\n",
    "            if j == 'n':\n",
    "                count[13] = count[13] + 1\n",
    "            if j == 'o':\n",
    "                count[14] = count[14] + 1\n",
    "            if j == 'p':\n",
    "                count[15] = count[15] + 1\n",
    "            if j == 'q':\n",
    "                count[16] = count[16] + 1\n",
    "            if j == 'r':\n",
    "                count[17] = count[17] + 1\n",
    "            if j == 's':\n",
    "                count[18] = count[18] + 1\n",
    "            if j == 't':\n",
    "                count[19] = count[19] + 1\n",
    "            if j == 'u':\n",
    "                count[20] = count[20] + 1\n",
    "            if j == 'v':\n",
    "                count[21] = count[21] + 1\n",
    "            if j == 'w':\n",
    "                count[22] = count[22] + 1\n",
    "            if j == 'x':\n",
    "                count[23] = count[23] + 1\n",
    "            if j == 'y':\n",
    "                count[24] = count[24] + 1\n",
    "            if j == 'z':\n",
    "                count[25] = count[25] + 1\n",
    "            if j == ' ':\n",
    "                count[26] = count[26] + 1\n",
    "    return(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bag-of-words vector count for e10.txt is:\n",
      "[199, 47, 70, 86, 352, 78, 47, 143, 170, 1, 15, 124, 59, 191, 236, 38, 3, 147, 194, 272, 86, 35, 57, 2, 43, 2, 618]\n"
     ]
    }
   ],
   "source": [
    "e_10_count_vec = Count_vec(X[11], Y[11])\n",
    "print(\"The bag-of-words vector count for e10.txt is:\\n\" + str(e_10_count_vec))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_given_prior(word_bag):\n",
    "    summed = [0.0, 0.0, 0.0]\n",
    "    summed[0] = sum(np.nan_to_num(word_bag*np.log(e_theta),  posinf=np.inf, neginf=-np.inf))\n",
    "    summed[1] = sum(np.nan_to_num(word_bag*np.log(j_theta),  posinf=np.inf, neginf=-np.inf))\n",
    "    summed[2] = sum(np.nan_to_num(word_bag*np.log(s_theta),  posinf=np.inf, neginf=-np.inf))\n",
    "    return(summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_given_prior(word_bag):\n",
    "    summed = [0.0, 0.0, 0.0]\n",
    "    summed[0] = sum(np.nan_to_num(word_bag*np.log(e_theta),  posinf=0, neginf=0))\n",
    "    summed[1] = sum(np.nan_to_num(word_bag*np.log(j_theta),  posinf=0, neginf=0))\n",
    "    summed[2] = sum(np.nan_to_num(word_bag*np.log(s_theta),  posinf=0, neginf=0))\n",
    "    return(summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n0/8fxhskld1wsc76dqzmh0f_9w0000gn/T/ipykernel_35298/4100122692.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  summed[1] = sum(np.nan_to_num(word_bag*np.log(j_theta),  posinf=0, neginf=0))\n"
     ]
    }
   ],
   "source": [
    "e_10_prob = prob_given_prior(e_10_count_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log[p(x|y=e)] is: -9346.192\n",
      "The log[p(x|y=j)] is: -10398.096\n",
      "The log[p(x|y=s)] is: -10081.8\n"
     ]
    }
   ],
   "source": [
    "print(\"The log[p(x|y=e)] is: \" + str(np.round(e_10_prob[0], 3)) + \"\\nThe log[p(x|y=j)] is: \" + \n",
    "str(np.round(e_10_prob[1], 3)) + \"\\nThe log[p(x|y=s)] is: \" + \n",
    "str(np.round(e_10_prob[2], 3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lang(prob_dist):\n",
    "    lang_type = ' '\n",
    "    max_index = prob_dist.index(np.max(prob_dist))\n",
    "    if max_index == 0:\n",
    "        lang_type = 'e'\n",
    "    elif max_index == 1:\n",
    "        lang_type = 'j'\n",
    "    elif max_index == 2:\n",
    "        lang_type = 's'\n",
    "    return(lang_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_10_pred = predict_lang(e_10_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e10.txt is classified as: e\n"
     ]
    }
   ],
   "source": [
    "print(\"e10.txt is classified as: \" + str(e_10_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_text(text, langs):\n",
    "    text_vec = Count_vec(text, langs)\n",
    "    text_prob = prob_given_prior(text_vec)\n",
    "    text_pred = predict_lang(text_prob)\n",
    "    return(text_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n0/8fxhskld1wsc76dqzmh0f_9w0000gn/T/ipykernel_35298/4100122692.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  summed[1] = sum(np.nan_to_num(word_bag*np.log(j_theta),  posinf=0, neginf=0))\n",
      "/var/folders/n0/8fxhskld1wsc76dqzmh0f_9w0000gn/T/ipykernel_35298/4100122692.py:4: RuntimeWarning: invalid value encountered in multiply\n",
      "  summed[1] = sum(np.nan_to_num(word_bag*np.log(j_theta),  posinf=0, neginf=0))\n"
     ]
    }
   ],
   "source": [
    "Y_pred = ['']*60\n",
    "for i in range(0,60):\n",
    "    Y_pred[i] = predict_from_text(X[i], Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0, 10,  0],\n",
       "       [ 0,  0, 10]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y[10:20]+Y[30:40]+Y[50:60], Y_pred[10:20]+Y_pred[30:40]+Y_pred[50:60])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_e10 = ''.join(random.sample(X[10], len(X[10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n0/8fxhskld1wsc76dqzmh0f_9w0000gn/T/ipykernel_35298/4100122692.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  summed[1] = sum(np.nan_to_num(word_bag*np.log(j_theta),  posinf=0, neginf=0))\n"
     ]
    }
   ],
   "source": [
    "shuffled_e10_pred = predict_from_text(shuffled_e10, Y[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After shuffling e10.txt, the shuffled text was classified correctly as: e\n"
     ]
    }
   ],
   "source": [
    "print(\"After shuffling e10.txt, the shuffled text was classified correctly as: \" + shuffled_e10_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffling does not change the classification as our model uses the distribution of letters to determine language, regardless of order.\n"
     ]
    }
   ],
   "source": [
    "print(\"Suffling does not change the classification as our model uses the distribution of letters to determine language, regardless of order.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset = datasets.MNIST(root='data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = DataLoader(mnist_trainset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    imag, labl = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.matrix(np.zeros((784, 300), dtype = np.float64))\n",
    "w2 = np.matrix(np.zeros((300, 200), dtype = np.float64))\n",
    "w3 = np.matrix(np.zeros((200, 10), dtype = np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.asarray(np.exp((sigmoid((sigmoid(((mnist_trainset[10000][0][0].reshape(-1,784).numpy())@w1)))@w2))@w3)).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "imag, lable = mnist_trainset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    sigma = 1/(1+np.exp(z))\n",
    "    return(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mynn_probs(train_in):\n",
    "    probs_out = np.asarray(np.exp((sigmoid((sigmoid(((train_in.reshape(-1,784).numpy())@w1)))@w2))@w3)).reshape(-1)\n",
    "    return(probs_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_in_1, label_1):\n",
    "    z1 = (train_in_1.reshape(-1,784).numpy())@w1\n",
    "    z2 = (sigmoid(((train_in_1.reshape(-1,784).numpy())@w1)))@w2\n",
    "    z3 = sigmoid((sigmoid(((train_in_1.reshape(-1,784).numpy())@w1)))@w2)@w3\n",
    "    y_hat = np.argmax(mynn_probs(train_in_1))\n",
    "    dL_dz3 = np.array(y_hat - label_1)\n",
    "    dL_dw3 = dL_dz3*(sigmoid(z2))\n",
    "    print(z1.shape, (1-sigmoid(z2)).shape, z3.shape)\n",
    "    dL_dw2 = (sigmoid(z1).T@(1-sigmoid(z2))).T@z3*dL_dz3\n",
    "    dL_dw1 = (train_in_1.reshape(-1,784).numpy())@(1-sigmoid(z1))@z2@(1-sigmoid(z2))@z3*dL_dz3\n",
    "    w3_n = w3 - alpha*dL_dw3\n",
    "    w2_n = w2 - alpha*dL_dw2\n",
    "    w1_n = w1 - alpha*dL_dw1\n",
    "    return(y_hat, w3_n, w2_n, w1_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300) (1, 200) (1, 10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 300)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n0/8fxhskld1wsc76dqzmh0f_9w0000gn/T/ipykernel_35298/1499064882.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_trainset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/n0/8fxhskld1wsc76dqzmh0f_9w0000gn/T/ipykernel_35298/558607276.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(train_in_1, label_1)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdL_dw3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdL_dz3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdL_dw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mz3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdL_dz3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdL_dw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_in_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mz3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdL_dz3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mw3_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw3\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdL_dw3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 300)"
     ]
    }
   ],
   "source": [
    "training(mnist_trainset[10000][0][0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynn_probs(mnist_trainset[10000][0][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset = datasets.MNIST(root='data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size1 = 300\n",
    "hidden_size2 = 200\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mynnmodel(nn.Module):\n",
    "       def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n",
    "        super().__init__()\n",
    "        # hidden layer 1\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size1)\n",
    "        # hidden layer 2\n",
    "        self.linear2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        # output layer\n",
    "        self.linear_output = nn.Linear(hidden_size2, num_classes)\n",
    "\n",
    "        def forward(self, xb):\n",
    "            xb = xb.reshape(-1, 784) # -1 so that it will work for different batch sizes\n",
    "            # Get intermediate outputs using hidden layer\n",
    "            out = self.linear1(xb)\n",
    "            # Apply activation function\n",
    "            out = F.sigmoid(out)\n",
    "            # Get predictions using output layer\n",
    "            out = self.linear2(out)\n",
    "\n",
    "            out = F.sigmoid(out)\n",
    "\n",
    "            out = self.linear_output(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = random_split(mnist_trainset, [59000, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# shuffle so that batches in each epoch are different, and this randomization helps generalize and speed up training\n",
    "train_loader = DataLoader(train, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "# val is only used for evaluating the model, so no need to shuffle\n",
    "val_loader = DataLoader(validation, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28 # 784 weights to train, 1 for each pixel\n",
    "hidden_size1 = 300\n",
    "hidden_size2 = 200\n",
    "num_classes = 10 # 10 outputs, 10 biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1) # probs shape is (128, 10), apply max to 10 class dim; max returns largest element and index of it\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds)), preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnistnnmodel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n",
    "        super().__init__()\n",
    "        # hidden layer 1\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size1)\n",
    "        # hidden layer 2\n",
    "        self.linear2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        # output layer\n",
    "        self.linear_output = nn.Linear(hidden_size2, num_classes)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784) # -1 so that it will work for different batch sizes\n",
    "        # Get intermediate outputs using hidden layer\n",
    "        out = self.linear1(xb)\n",
    "        # Apply activation function\n",
    "        out = F.sigmoid(out)\n",
    "        # Get predictions using output layer\n",
    "        out = self.linear2(out)\n",
    "\n",
    "        out = F.sigmoid(out)\n",
    "\n",
    "        out = self.linear_output(out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images,labels = batch\n",
    "        out = self(images)                            # generate predictions\n",
    "        loss = F.cross_entropy(out, labels)           # compute loss\n",
    "        acc,preds = accuracy(out, labels)             # calculate accuracy\n",
    "        return {'train_loss': loss, 'train_acc':acc}\n",
    "    \n",
    "    def train_epoch_end(self, outputs):\n",
    "        batch_losses = [x['train_loss'] for x in outputs]   # get all the batches loss\n",
    "        epoch_loss = torch.stack(batch_losses).mean()       # combine losses\n",
    "        batch_accs = [x['train_acc'] for x in outputs]      # get all the batches acc\n",
    "        epoch_acc = torch.stack(batch_accs).mean()          # combine accuracies\n",
    "        return {'train_loss': epoch_loss.item(), 'train_acc': epoch_acc.item()}\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images,labels = batch\n",
    "        out = self(images)                       # generate predictions\n",
    "        loss = F.cross_entropy(out, labels)      # compute loss\n",
    "        acc,preds = accuracy(out, labels)        # calculate accuracy and get predictions\n",
    "        return {'val_loss': loss.detach(), 'val_acc':acc, 'preds':preds, 'labels':labels} # detach extracts only the needed number, or other numbers will crowd memory\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]     # get all the batches loss\n",
    "        epoch_loss = torch.stack(batch_losses).mean()       # combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]        # get all the batches acc\n",
    "        epoch_acc = torch.stack(batch_accs).mean()          # combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "\n",
    "    # this is for printing out the results after each epoch\n",
    "    def epoch_end(self, epoch, train_result, val_result):\n",
    "        print('Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}'.format(epoch+1, train_result['train_loss'], train_result['train_acc'], val_result['val_loss'], val_result['val_acc']))\n",
    "\n",
    "    def test_prediction(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()                           # combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()                              # combine accuracies\n",
    "        batch_preds = [pred for x in outputs for pred in x['preds'].tolist()]   # combine predictions\n",
    "        batch_labels = [lab for x in outputs for lab in x['labels'].tolist()]   # combine labels\n",
    "        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item(), 'test_preds': batch_preds, 'test_labels': batch_labels}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, val_loader, epochs, lr, opt_func=torch.optim.SGD):\n",
    "    history = {}\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Training phase\n",
    "        train_outputs = []\n",
    "        for batch in train_loader:\n",
    "            outputs = model.training_step(batch)              # compute loss and accuracy\n",
    "            loss = outputs['train_loss']                      # get loss\n",
    "            train_outputs.append(outputs)\n",
    "            loss.backward()                                   # compute gradients\n",
    "            optimizer.step()                                  # update weights \n",
    "            optimizer.zero_grad()                             # reset gradients to zero\n",
    "        train_results = model.train_epoch_end(train_outputs)  # get the train average loss and acc for each epoch\n",
    "            \n",
    "        # Validation phase\n",
    "        val_results = evaluate(model, val_loader)\n",
    "        \n",
    "        # print results\n",
    "        model.epoch_end(epoch, train_results, val_results)\n",
    "                \n",
    "        # save results to dictionary\n",
    "        to_add = {'train_loss': train_results['train_loss'], 'train_acc': train_results['train_acc'],\n",
    "                 'val_loss': val_results['val_loss'], 'val_acc': val_results['val_acc']}\n",
    "        for key,val in to_add.items():\n",
    "            if key in history:\n",
    "                history[key].append(val)\n",
    "            else:\n",
    "                history[key] = [val]\n",
    "                \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    images = to_device(images, device)\n",
    "    print(images.device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device) # yield will stop here, perform other steps, and the resumes to the next loop/batch\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "val_loader = DeviceDataLoader(val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mnistnnmodel(\n",
       "  (linear1): Linear(in_features=784, out_features=300, bias=True)\n",
       "  (linear2): Linear(in_features=300, out_features=200, bias=True)\n",
       "  (linear_output): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 784 #784\n",
    "hidden_size = 128\n",
    "lr = 0.1\n",
    "num_epochs = 10\n",
    "\n",
    "modelNN = Mnistnnmodel(input_size, hidden_size1, hidden_size2, num_classes=10)  \n",
    "to_device(modelNN, device) # move model parameters to the same device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader] # perform val for each batch\n",
    "    return model.validation_epoch_end(outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], train_loss: 2.2760, train_acc: 0.1560, val_loss: 2.1665, val_acc: 0.2992\n",
      "Epoch [2], train_loss: 1.5723, train_acc: 0.5081, val_loss: 1.0347, val_acc: 0.6767\n",
      "Epoch [3], train_loss: 0.8024, train_acc: 0.7564, val_loss: 0.6739, val_acc: 0.7995\n",
      "Epoch [4], train_loss: 0.5672, train_acc: 0.8357, val_loss: 0.5325, val_acc: 0.8471\n",
      "Epoch [5], train_loss: 0.4617, train_acc: 0.8678, val_loss: 0.4653, val_acc: 0.8628\n",
      "Epoch [6], train_loss: 0.4082, train_acc: 0.8839, val_loss: 0.4241, val_acc: 0.8771\n",
      "Epoch [7], train_loss: 0.3772, train_acc: 0.8925, val_loss: 0.4130, val_acc: 0.8747\n",
      "Epoch [8], train_loss: 0.3566, train_acc: 0.8978, val_loss: 0.4024, val_acc: 0.8786\n",
      "Epoch [9], train_loss: 0.3411, train_acc: 0.9020, val_loss: 0.3769, val_acc: 0.8947\n",
      "Epoch [10], train_loss: 0.3278, train_acc: 0.9065, val_loss: 0.3699, val_acc: 0.8954\n"
     ]
    }
   ],
   "source": [
    "history = fit(modelNN, train_loader, val_loader, num_epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict(model, test_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in test_loader] # perform testing for each batch\n",
    "    results = model.test_prediction(outputs)                          # get the results\n",
    "    print('test_loss: {:.4f}, test_acc: {:.4f}'.format(results['test_loss'], results['test_acc']))\n",
    "    return results['test_preds'], results['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.3104, test_acc: 0.9095\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(mnist_testset, batch_size=256)\n",
    "preds,labels = test_predict(modelNN, test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keeping track as I change train size\n",
    "\n",
    "Train 59,000: train--0.9065, test--0.9095\n",
    "Train 50,000: train--0.9005, test--0.9059\n",
    "Train 30,000: train--0.8626, test--0.8782\n",
    "Train 10,000: train--0.5979, test--0.5416\n",
    "Train 5,000: train--0.2121, test--0.0965\n",
    "Train 1,000: train--0.1090, test--0.1037\n",
    "Train 100: train--0.1500, test--0.1019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 540x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots(1,figsize=(7.5,6), facecolor='white')\n",
    "ax.grid(color='gray',axis='both',alpha=0.2)\n",
    "ax.tick_params(left=True, bottom=True, labelleft = True, labelbottom=True, labelsize=14)\n",
    "\n",
    "ax.set_xlabel('Training Samples', fontsize=18)\n",
    "ax.set_ylabel('Accuracy', fontsize=18)\n",
    "ax.set_xlim(0,60000)\n",
    "ax.set_ylim(0,1)\n",
    "\n",
    "plt.plot([100, 1000, 5000, 10000, 30000, 50000, 59000], [0.15, 0.109, 0.2121, 0.5979, 0.8626, 0.9005, 0.9065])\n",
    "plt.plot([100, 1000, 5000, 10000, 30000, 50000, 59000], [0.1019, 0.1037, 0.0965, 0.5416, 0.8782, 0.9059, 0.9095])\n",
    "\n",
    "plt.savefig(\"/Users/elvis/Documents/Graduate/Courses/CS760/HW4/Problem 3.3.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e643d4fd3ec1db81d393551f271cf70d6b70a41f0b198b244df41a746c6c6fef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
