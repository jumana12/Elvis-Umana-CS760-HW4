{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ['']*60\n",
    "Y = ['']*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,20):\n",
    "    X[i] = open('/Users/elvis/Downloads/hw4-1/languageID/e' + str(i) + '.txt','r').read()\n",
    "    X[i+20] = open('/Users/elvis/Downloads/hw4-1/languageID/j' + str(i) + '.txt','r').read()\n",
    "    X[i+40] = open('/Users/elvis/Downloads/hw4-1/languageID/s' + str(i) + '.txt','r').read()\n",
    "    Y[i] = 'e'\n",
    "    Y[i+20] = 'j'\n",
    "    Y[i+40] = 's'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prior(lang_target, text, langs):\n",
    "    count = 0\n",
    "    for i in langs:\n",
    "        if i == lang_target:\n",
    "            count = count + 1\n",
    "    prior_calc = (count + 0.5)/(len(langs) + 3*0.5)\n",
    "    return(prior_calc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_prior = Prior('e', X[:10] + X[20:30] + X[40:50], Y[:10] + Y[20:30] + Y[40:50])\n",
    "j_prior = Prior('j', X[:10] + X[20:30] + X[40:50], Y[:10] + Y[20:30] + Y[40:50])\n",
    "s_prior = Prior('s', X[:10] + X[20:30] + X[40:50], Y[:10] + Y[20:30] + Y[40:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Y = e) = 0.3333333333333333\n",
      "P(Y = j) = 0.3333333333333333\n",
      "P(Y = s) = 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"P(Y = e) = \" + str(e_prior) + \"\\nP(Y = j) = \" + str(j_prior) + \"\\nP(Y = s) = \" + str(s_prior))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Theta_vec(text, langs):\n",
    "    count = [0]*27\n",
    "    theta = [0.0]*27\n",
    "    theta_corrected = [0.0]*27\n",
    "    for i in text:\n",
    "        for j in i:\n",
    "            if j == 'a':\n",
    "                count[0] = count[0] + 1\n",
    "            if j == 'b':\n",
    "                count[1] = count[1] + 1\n",
    "            if j == 'c':\n",
    "                count[2] = count[2] + 1\n",
    "            if j == 'd':\n",
    "                count[3] = count[3] + 1\n",
    "            if j == 'e':\n",
    "                count[4] = count[4] + 1\n",
    "            if j == 'f':\n",
    "                count[5] = count[5] + 1\n",
    "            if j == 'g':\n",
    "                count[6] = count[6] + 1\n",
    "            if j == 'h':\n",
    "                count[7] = count[7] + 1\n",
    "            if j == 'i':\n",
    "                count[8] = count[8] + 1\n",
    "            if j == 'j':\n",
    "                count[9] = count[9] + 1\n",
    "            if j == 'k':\n",
    "                count[10] = count[10] + 1\n",
    "            if j == 'l':\n",
    "                count[11] = count[11] + 1\n",
    "            if j == 'm':\n",
    "                count[12] = count[12] + 1\n",
    "            if j == 'n':\n",
    "                count[13] = count[13] + 1\n",
    "            if j == 'o':\n",
    "                count[14] = count[14] + 1\n",
    "            if j == 'p':\n",
    "                count[15] = count[15] + 1\n",
    "            if j == 'q':\n",
    "                count[16] = count[16] + 1\n",
    "            if j == 'r':\n",
    "                count[17] = count[17] + 1\n",
    "            if j == 's':\n",
    "                count[18] = count[18] + 1\n",
    "            if j == 't':\n",
    "                count[19] = count[19] + 1\n",
    "            if j == 'u':\n",
    "                count[20] = count[20] + 1\n",
    "            if j == 'v':\n",
    "                count[21] = count[21] + 1\n",
    "            if j == 'w':\n",
    "                count[22] = count[22] + 1\n",
    "            if j == 'x':\n",
    "                count[23] = count[23] + 1\n",
    "            if j == 'y':\n",
    "                count[24] = count[24] + 1\n",
    "            if j == 'z':\n",
    "                count[25] = count[25] + 1\n",
    "            if j == ' ':\n",
    "                count[26] = count[26] + 1\n",
    "    for i in range(0,27):\n",
    "        theta[i] = count[i]/sum(count)\n",
    "        theta_corrected[i] = (count[i]+0.5)/(sum(count) + 27*0.5)\n",
    "    return(theta_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The multinomial parameter vector for English is:\n",
      "[0.06  0.011 0.022 0.022 0.105 0.019 0.017 0.047 0.055 0.001 0.004 0.029\n",
      " 0.021 0.058 0.064 0.017 0.001 0.054 0.066 0.08  0.027 0.009 0.015 0.001\n",
      " 0.014 0.001 0.179]\n"
     ]
    }
   ],
   "source": [
    "e_theta = Theta_vec(X[:10], Y[:10])\n",
    "print(\"The multinomial parameter vector for English is:\\n\" + str(np.round(e_theta, 3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The multinomial parameter vector for Japanese is:\n",
      "[0.132 0.011 0.005 0.017 0.06  0.004 0.014 0.032 0.097 0.002 0.057 0.001\n",
      " 0.04  0.057 0.091 0.001 0.    0.043 0.042 0.057 0.071 0.    0.02  0.\n",
      " 0.014 0.008 0.123]\n"
     ]
    }
   ],
   "source": [
    "j_theta = Theta_vec(X[20:30], Y[:10])\n",
    "print(\"The multinomial parameter vector for Japanese is:\\n\" + str(np.round(j_theta, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The multinomial parameter vector for Spanish is:\n",
      "[0.105 0.008 0.038 0.04  0.114 0.009 0.007 0.005 0.05  0.007 0.    0.053\n",
      " 0.026 0.054 0.072 0.024 0.008 0.059 0.066 0.036 0.034 0.006 0.    0.002\n",
      " 0.008 0.003 0.168]\n"
     ]
    }
   ],
   "source": [
    "s_theta = Theta_vec(X[40:50], Y[:10])\n",
    "print(\"The multinomial parameter vector for Spanish is:\\n\" + str(np.round(s_theta, 3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Count_vec(text, langs):\n",
    "    count = [0]*27\n",
    "    for i in text:\n",
    "        for j in i:\n",
    "            if j == 'a':\n",
    "                count[0] = count[0] + 1\n",
    "            if j == 'b':\n",
    "                count[1] = count[1] + 1\n",
    "            if j == 'c':\n",
    "                count[2] = count[2] + 1\n",
    "            if j == 'd':\n",
    "                count[3] = count[3] + 1\n",
    "            if j == 'e':\n",
    "                count[4] = count[4] + 1\n",
    "            if j == 'f':\n",
    "                count[5] = count[5] + 1\n",
    "            if j == 'g':\n",
    "                count[6] = count[6] + 1\n",
    "            if j == 'h':\n",
    "                count[7] = count[7] + 1\n",
    "            if j == 'i':\n",
    "                count[8] = count[8] + 1\n",
    "            if j == 'j':\n",
    "                count[9] = count[9] + 1\n",
    "            if j == 'k':\n",
    "                count[10] = count[10] + 1\n",
    "            if j == 'l':\n",
    "                count[11] = count[11] + 1\n",
    "            if j == 'm':\n",
    "                count[12] = count[12] + 1\n",
    "            if j == 'n':\n",
    "                count[13] = count[13] + 1\n",
    "            if j == 'o':\n",
    "                count[14] = count[14] + 1\n",
    "            if j == 'p':\n",
    "                count[15] = count[15] + 1\n",
    "            if j == 'q':\n",
    "                count[16] = count[16] + 1\n",
    "            if j == 'r':\n",
    "                count[17] = count[17] + 1\n",
    "            if j == 's':\n",
    "                count[18] = count[18] + 1\n",
    "            if j == 't':\n",
    "                count[19] = count[19] + 1\n",
    "            if j == 'u':\n",
    "                count[20] = count[20] + 1\n",
    "            if j == 'v':\n",
    "                count[21] = count[21] + 1\n",
    "            if j == 'w':\n",
    "                count[22] = count[22] + 1\n",
    "            if j == 'x':\n",
    "                count[23] = count[23] + 1\n",
    "            if j == 'y':\n",
    "                count[24] = count[24] + 1\n",
    "            if j == 'z':\n",
    "                count[25] = count[25] + 1\n",
    "            if j == ' ':\n",
    "                count[26] = count[26] + 1\n",
    "    return(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bag-of-words vector count for e10.txt is:\n",
      "[199, 47, 70, 86, 352, 78, 47, 143, 170, 1, 15, 124, 59, 191, 236, 38, 3, 147, 194, 272, 86, 35, 57, 2, 43, 2, 618]\n"
     ]
    }
   ],
   "source": [
    "e_10_count_vec = Count_vec(X[11], Y[11])\n",
    "print(\"The bag-of-words vector count for e10.txt is:\\n\" + str(e_10_count_vec))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_given_prior(word_bag):\n",
    "    summed = [0.0, 0.0, 0.0]\n",
    "    summed[0] = sum(np.nan_to_num(word_bag*np.log(e_theta),  posinf=np.inf, neginf=-np.inf))\n",
    "    summed[1] = sum(np.nan_to_num(word_bag*np.log(j_theta),  posinf=np.inf, neginf=-np.inf))\n",
    "    summed[2] = sum(np.nan_to_num(word_bag*np.log(s_theta),  posinf=np.inf, neginf=-np.inf))\n",
    "    return(summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_given_prior(word_bag):\n",
    "    summed = [0.0, 0.0, 0.0]\n",
    "    summed[0] = sum(np.nan_to_num(word_bag*np.log(e_theta),  posinf=0, neginf=0))\n",
    "    summed[1] = sum(np.nan_to_num(word_bag*np.log(j_theta),  posinf=0, neginf=0))\n",
    "    summed[2] = sum(np.nan_to_num(word_bag*np.log(s_theta),  posinf=0, neginf=0))\n",
    "    return(summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_10_prob = prob_given_prior(e_10_count_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log[p(x|y=e)] is: -9346.212\n",
      "The log[p(x|y=j)] is: -10407.284\n",
      "The log[p(x|y=s)] is: -10056.252\n"
     ]
    }
   ],
   "source": [
    "print(\"The log[p(x|y=e)] is: \" + str(np.round(e_10_prob[0], 3)) + \"\\nThe log[p(x|y=j)] is: \" + \n",
    "str(np.round(e_10_prob[1], 3)) + \"\\nThe log[p(x|y=s)] is: \" + \n",
    "str(np.round(e_10_prob[2], 3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lang(prob_dist):\n",
    "    lang_type = ' '\n",
    "    max_index = prob_dist.index(np.max(prob_dist))\n",
    "    if max_index == 0:\n",
    "        lang_type = 'e'\n",
    "    elif max_index == 1:\n",
    "        lang_type = 'j'\n",
    "    elif max_index == 2:\n",
    "        lang_type = 's'\n",
    "    return(lang_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_10_pred = predict_lang(e_10_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log[p(x|y=e)] is: -3115.404\n",
      "The log[p(x|y=j)] is: -3469.095\n",
      "The log[p(x|y=s)] is: -3352.084\n"
     ]
    }
   ],
   "source": [
    "print(\"The log[p(x|y=e)] is: \" + str(np.round(e_10_prob[0]/3, 3)) + \"\\nThe log[p(x|y=j)] is: \" + \n",
    "str(np.round(e_10_prob[1]/3, 3)) + \"\\nThe log[p(x|y=s)] is: \" + \n",
    "str(np.round(e_10_prob[2]/3, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e10.txt is classified as: e\n"
     ]
    }
   ],
   "source": [
    "print(\"e10.txt is classified as: \" + str(e_10_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_text(text, langs):\n",
    "    text_vec = Count_vec(text, langs)\n",
    "    text_prob = prob_given_prior(text_vec)\n",
    "    text_pred = predict_lang(text_prob)\n",
    "    return(text_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = ['']*60\n",
    "for i in range(0,60):\n",
    "    Y_pred[i] = predict_from_text(X[i], Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0, 10,  0],\n",
       "       [ 0,  0, 10]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y[10:20]+Y[30:40]+Y[50:60], Y_pred[10:20]+Y_pred[30:40]+Y_pred[50:60])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_e10 = ''.join(random.sample(X[10], len(X[10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_e10_pred = predict_from_text(shuffled_e10, Y[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After shuffling e10.txt, the shuffled text was classified correctly as: e\n"
     ]
    }
   ],
   "source": [
    "print(\"After shuffling e10.txt, the shuffled text was classified correctly as: \" + shuffled_e10_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffling does not change the classification as our model uses the distribution of letters to determine language, regardless of order.\n"
     ]
    }
   ],
   "source": [
    "print(\"Suffling does not change the classification as our model uses the distribution of letters to determine language, regardless of order.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset = datasets.MNIST(root='data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = DataLoader(mnist_trainset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    imag, labl = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.matrix(np.zeros((784, 300), dtype = np.float64))\n",
    "w2 = np.matrix(np.zeros((300, 200), dtype = np.float64))\n",
    "w3 = np.matrix(np.zeros((200, 10), dtype = np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.asarray(np.exp((sigmoid((sigmoid(((mnist_trainset[10000][0][0].reshape(-1,784).numpy())@w1)))@w2))@w3)).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "imag, lable = mnist_trainset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    sigma = 1/(1+np.exp(z))\n",
    "    return(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mynn_probs(train_in):\n",
    "    probs_out = np.asarray(np.exp((sigmoid((sigmoid(((train_in.reshape(-1,784).numpy())@w1)))@w2))@w3)).reshape(-1)\n",
    "    return(probs_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_in_1, label_1):\n",
    "    z1 = (train_in_1.reshape(-1,784).numpy())@w1\n",
    "    z2 = (sigmoid(((train_in_1.reshape(-1,784).numpy())@w1)))@w2\n",
    "    z3 = sigmoid((sigmoid(((train_in_1.reshape(-1,784).numpy())@w1)))@w2)@w3\n",
    "    y_hat = np.argmax(mynn_probs(train_in_1))\n",
    "    dL_dz3 = np.array(y_hat - label_1)\n",
    "    dL_dw3 = dL_dz3*(sigmoid(z2))\n",
    "    print(z1.shape, (1-sigmoid(z2)).shape, z3.shape)\n",
    "    dL_dw2 = (sigmoid(z1).T@(1-sigmoid(z2))).T@z3*dL_dz3\n",
    "    dL_dw1 = (train_in_1.reshape(-1,784).numpy())@(1-sigmoid(z1))@z2@(1-sigmoid(z2))@z3*dL_dz3\n",
    "    w3_n = w3 - alpha*dL_dw3\n",
    "    w2_n = w2 - alpha*dL_dw2\n",
    "    w1_n = w1 - alpha*dL_dw1\n",
    "    return(y_hat, w3_n, w2_n, w1_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300) (1, 200) (1, 10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 300)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n0/8fxhskld1wsc76dqzmh0f_9w0000gn/T/ipykernel_35298/1499064882.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_trainset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/n0/8fxhskld1wsc76dqzmh0f_9w0000gn/T/ipykernel_35298/558607276.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(train_in_1, label_1)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdL_dw3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdL_dz3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdL_dw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mz3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdL_dz3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdL_dw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_in_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mz3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdL_dz3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mw3_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw3\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdL_dw3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 300)"
     ]
    }
   ],
   "source": [
    "training(mnist_trainset[10000][0][0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynn_probs(mnist_trainset[10000][0][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='data', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset = datasets.MNIST(root='data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size1 = 300\n",
    "hidden_size2 = 200\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mynnmodel(nn.Module):\n",
    "       def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n",
    "        super().__init__()\n",
    "        # hidden layer 1\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size1)\n",
    "        # hidden layer 2\n",
    "        self.linear2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        # output layer\n",
    "        self.linear_output = nn.Linear(hidden_size2, num_classes)\n",
    "\n",
    "        def forward(self, xb):\n",
    "            xb = xb.reshape(-1, 784) # -1 so that it will work for different batch sizes\n",
    "            # Get intermediate outputs using hidden layer\n",
    "            out = self.linear1(xb)\n",
    "            # Apply activation function\n",
    "            out = F.sigmoid(out)\n",
    "            # Get predictions using output layer\n",
    "            out = self.linear2(out)\n",
    "\n",
    "            out = F.sigmoid(out)\n",
    "\n",
    "            out = self.linear_output(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = random_split(mnist_trainset, [59000, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# shuffle so that batches in each epoch are different, and this randomization helps generalize and speed up training\n",
    "train_loader = DataLoader(train, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "# val is only used for evaluating the model, so no need to shuffle\n",
    "val_loader = DataLoader(validation, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28 # 784 weights to train, 1 for each pixel\n",
    "hidden_size1 = 300\n",
    "hidden_size2 = 200\n",
    "num_classes = 10 # 10 outputs, 10 biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1) # probs shape is (128, 10), apply max to 10 class dim; max returns largest element and index of it\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds)), preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnistnnmodel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n",
    "        super().__init__()\n",
    "        # hidden layer 1\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size1)\n",
    "        # hidden layer 2\n",
    "        self.linear2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        # output layer\n",
    "        self.linear_output = nn.Linear(hidden_size2, num_classes)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784) # -1 so that it will work for different batch sizes\n",
    "        # Get intermediate outputs using hidden layer\n",
    "        out = self.linear1(xb)\n",
    "        # Apply activation function\n",
    "        out = F.sigmoid(out)\n",
    "        # Get predictions using output layer\n",
    "        out = self.linear2(out)\n",
    "\n",
    "        out = F.sigmoid(out)\n",
    "\n",
    "        out = self.linear_output(out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images,labels = batch\n",
    "        out = self(images)                            # generate predictions\n",
    "        loss = F.cross_entropy(out, labels)           # compute loss\n",
    "        acc,preds = accuracy(out, labels)             # calculate accuracy\n",
    "        return {'train_loss': loss, 'train_acc':acc}\n",
    "    \n",
    "    def train_epoch_end(self, outputs):\n",
    "        batch_losses = [x['train_loss'] for x in outputs]   # get all the batches loss\n",
    "        epoch_loss = torch.stack(batch_losses).mean()       # combine losses\n",
    "        batch_accs = [x['train_acc'] for x in outputs]      # get all the batches acc\n",
    "        epoch_acc = torch.stack(batch_accs).mean()          # combine accuracies\n",
    "        return {'train_loss': epoch_loss.item(), 'train_acc': epoch_acc.item()}\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images,labels = batch\n",
    "        out = self(images)                       # generate predictions\n",
    "        loss = F.cross_entropy(out, labels)      # compute loss\n",
    "        acc,preds = accuracy(out, labels)        # calculate accuracy and get predictions\n",
    "        return {'val_loss': loss.detach(), 'val_acc':acc, 'preds':preds, 'labels':labels} # detach extracts only the needed number, or other numbers will crowd memory\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]     # get all the batches loss\n",
    "        epoch_loss = torch.stack(batch_losses).mean()       # combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]        # get all the batches acc\n",
    "        epoch_acc = torch.stack(batch_accs).mean()          # combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "\n",
    "    # this is for printing out the results after each epoch\n",
    "    def epoch_end(self, epoch, train_result, val_result):\n",
    "        print('Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}'.format(epoch+1, train_result['train_loss'], train_result['train_acc'], val_result['val_loss'], val_result['val_acc']))\n",
    "\n",
    "    def test_prediction(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()                           # combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()                              # combine accuracies\n",
    "        batch_preds = [pred for x in outputs for pred in x['preds'].tolist()]   # combine predictions\n",
    "        batch_labels = [lab for x in outputs for lab in x['labels'].tolist()]   # combine labels\n",
    "        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item(), 'test_preds': batch_preds, 'test_labels': batch_labels}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, val_loader, epochs, lr, opt_func=torch.optim.SGD):\n",
    "    history = {}\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Training phase\n",
    "        train_outputs = []\n",
    "        for batch in train_loader:\n",
    "            outputs = model.training_step(batch)              # compute loss and accuracy\n",
    "            loss = outputs['train_loss']                      # get loss\n",
    "            train_outputs.append(outputs)\n",
    "            loss.backward()                                   # compute gradients\n",
    "            optimizer.step()                                  # update weights \n",
    "            optimizer.zero_grad()                             # reset gradients to zero\n",
    "        train_results = model.train_epoch_end(train_outputs)  # get the train average loss and acc for each epoch\n",
    "            \n",
    "        # Validation phase\n",
    "        val_results = evaluate(model, val_loader)\n",
    "        \n",
    "        # print results\n",
    "        model.epoch_end(epoch, train_results, val_results)\n",
    "                \n",
    "        # save results to dictionary\n",
    "        to_add = {'train_loss': train_results['train_loss'], 'train_acc': train_results['train_acc'],\n",
    "                 'val_loss': val_results['val_loss'], 'val_acc': val_results['val_acc']}\n",
    "        for key,val in to_add.items():\n",
    "            if key in history:\n",
    "                history[key].append(val)\n",
    "            else:\n",
    "                history[key] = [val]\n",
    "                \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    images = to_device(images, device)\n",
    "    print(images.device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device) # yield will stop here, perform other steps, and the resumes to the next loop/batch\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "val_loader = DeviceDataLoader(val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mnistnnmodel(\n",
       "  (linear1): Linear(in_features=784, out_features=300, bias=True)\n",
       "  (linear2): Linear(in_features=300, out_features=200, bias=True)\n",
       "  (linear_output): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 784 #784\n",
    "hidden_size = 128\n",
    "lr = 0.1\n",
    "num_epochs = 10\n",
    "\n",
    "modelNN = Mnistnnmodel(input_size, hidden_size1, hidden_size2, num_classes=10)  \n",
    "to_device(modelNN, device) # move model parameters to the same device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader] # perform val for each batch\n",
    "    return model.validation_epoch_end(outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], train_loss: 2.2760, train_acc: 0.1560, val_loss: 2.1665, val_acc: 0.2992\n",
      "Epoch [2], train_loss: 1.5723, train_acc: 0.5081, val_loss: 1.0347, val_acc: 0.6767\n",
      "Epoch [3], train_loss: 0.8024, train_acc: 0.7564, val_loss: 0.6739, val_acc: 0.7995\n",
      "Epoch [4], train_loss: 0.5672, train_acc: 0.8357, val_loss: 0.5325, val_acc: 0.8471\n",
      "Epoch [5], train_loss: 0.4617, train_acc: 0.8678, val_loss: 0.4653, val_acc: 0.8628\n",
      "Epoch [6], train_loss: 0.4082, train_acc: 0.8839, val_loss: 0.4241, val_acc: 0.8771\n",
      "Epoch [7], train_loss: 0.3772, train_acc: 0.8925, val_loss: 0.4130, val_acc: 0.8747\n",
      "Epoch [8], train_loss: 0.3566, train_acc: 0.8978, val_loss: 0.4024, val_acc: 0.8786\n",
      "Epoch [9], train_loss: 0.3411, train_acc: 0.9020, val_loss: 0.3769, val_acc: 0.8947\n",
      "Epoch [10], train_loss: 0.3278, train_acc: 0.9065, val_loss: 0.3699, val_acc: 0.8954\n"
     ]
    }
   ],
   "source": [
    "history = fit(modelNN, train_loader, val_loader, num_epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict(model, test_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in test_loader] # perform testing for each batch\n",
    "    results = model.test_prediction(outputs)                          # get the results\n",
    "    print('test_loss: {:.4f}, test_acc: {:.4f}'.format(results['test_loss'], results['test_acc']))\n",
    "    return results['test_preds'], results['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.3104, test_acc: 0.9095\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(mnist_testset, batch_size=256)\n",
    "preds,labels = test_predict(modelNN, test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keeping track as I change train size\n",
    "\n",
    "Train 59,000: train--0.9065, test--0.9095\n",
    "Train 50,000: train--0.9005, test--0.9059\n",
    "Train 30,000: train--0.8626, test--0.8782\n",
    "Train 10,000: train--0.5979, test--0.5416\n",
    "Train 5,000: train--0.2121, test--0.0965\n",
    "Train 1,000: train--0.1090, test--0.1037\n",
    "Train 100: train--0.1500, test--0.1019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 540x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots(1,figsize=(7.5,6), facecolor='white')\n",
    "ax.grid(color='gray',axis='both',alpha=0.2)\n",
    "ax.tick_params(left=True, bottom=True, labelleft = True, labelbottom=True, labelsize=14)\n",
    "\n",
    "ax.set_xlabel('Training Samples', fontsize=18)\n",
    "ax.set_ylabel('Accuracy', fontsize=18)\n",
    "ax.set_xlim(0,60000)\n",
    "ax.set_ylim(0,1)\n",
    "\n",
    "plt.plot([100, 1000, 5000, 10000, 30000, 50000, 59000], [0.15, 0.109, 0.2121, 0.5979, 0.8626, 0.9005, 0.9065], label = \"Train\", color = \"blue\")\n",
    "plt.plot([100, 1000, 5000, 10000, 30000, 50000, 59000], [0.1019, 0.1037, 0.0965, 0.5416, 0.8782, 0.9059, 0.9095], label = \"Test\", color = \"red\")\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.savefig(\"/Users/elvis/Documents/Graduate/Courses/CS760/HW4/Problem 3.3.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e643d4fd3ec1db81d393551f271cf70d6b70a41f0b198b244df41a746c6c6fef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
